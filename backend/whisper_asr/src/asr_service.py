# whisper_asr/src/asr_service.py

import whisper
from .normalizer import normalize_text

# ğŸ”’ HARD-LOCK SAFE MODEL CONFIG (Mac-friendly)
WHISPER_MODEL_NAME = "medium"   # â† was large-v2 (too heavy)
DEVICE = "cpu"


class WhisperASRService:
    """
    Production-ready ASR service wrapper around OpenAI Whisper.

    - CPU-only (stable on Mac)
    - English decoding (romanized output)
    - Multilingual input (Hindi / Kannada / English)
    - Safe for streaming usage
    """

    def __init__(self):
        print(f"ğŸ”Š Loading Whisper model: {WHISPER_MODEL_NAME} ({DEVICE})")

        # Load model once (NO reloads)
        self.model = whisper.load_model(
            WHISPER_MODEL_NAME,
            device=DEVICE
        )

        print("âœ… Whisper model loaded")

    def transcribe(self, audio_path: str):
        """
        Transcribe an audio chunk.

        Returns:
            clean_text (str): normalized text (romanized if Hindi)
            detected_language (str)
            raw_text (str): raw Whisper output
        """

        result = self.model.transcribe(
            audio_path,
            task="transcribe",
            language="en",   # ğŸ”’ Force English decoding
            fp16=False       # ğŸ”’ CPU-safe
        )

        raw_text = result.get("text", "").strip()
        detected_language = result.get("language", "unknown")

        # Normalize ONCE (Hindi â†’ Romanized English)
        clean_text = normalize_text(raw_text)

        return clean_text, detected_language, raw_text
